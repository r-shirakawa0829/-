import streamlit as st
import feedparser
from streamlit_calendar import calendar
from datetime import datetime, date, timedelta
import re
import google.generativeai as genai

st.set_page_config(layout="wide", page_title="B2B Radar & AI Outreach")

# --- AIè¨­å®š ---
if "GEMINI_API_KEY" in st.secrets:
    genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
else:
    st.warning("Secretsã« GEMINI_API_KEY ã‚’ç™»éŒ²ã—ã¦ãã ã•ã„ã€‚")

# --- ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ï¼ˆãƒ¡ãƒ¢ãƒªï¼‰ã®ç®¡ç† ---
if "selected_date" not in st.session_state:
    st.session_state.selected_date = str(date.today())
# AIã®ç”Ÿæˆçµæœã‚’ä¿å­˜ã—ã¦ãŠãå ´æ‰€
if "ai_results" not in st.session_state:
    st.session_state.ai_results = {}

# --- ãƒ‹ãƒ¥ãƒ¼ã‚¹å–å¾— (PR TIMES, THE BRIDGE, Google News) ---
@st.cache_data(ttl=3600)
def fetch_b2b_news():
    feeds = {
        "ğŸš€ PR TIMES": "https://prtimes.jp/main/html/index/category_id/44/rdf.xml",
        "ğŸ’° THE BRIDGE": "https://thebridge.jp/feed",
        "ğŸ” Google News": "https://news.google.com/rss/search?q=(æ ªå¼ä¼šç¤¾+OR+åˆåŒä¼šç¤¾)+(è³‡é‡‘èª¿é”+OR+SaaS+OR+DX)+-NTT+-ãƒˆãƒ¨ã‚¿+-ã‚½ãƒ•ãƒˆãƒãƒ³ã‚¯+-ã‚½ãƒ‹ãƒ¼+when:7d&hl=ja&gl=JP&ceid=JP:ja"
    }
    all_events = []
    for source_name, url in feeds.items():
        feed = feedparser.parse(url)
        for entry in feed.entries:
            title = entry.title
            if any(x in title for x in ["æ±è¨¼", "ãƒ¡ã‚¬ãƒãƒ³ã‚¯", "å¤§ä¼æ¥­", "ã‚¹ã‚¤ãƒ¼ãƒ„", "ã‚³ã‚¹ãƒ¡"]): continue
            pub_dt = datetime(*entry.published_parsed[:6])
            date_str = pub_dt.strftime('%Y-%m-%d')
            company_match = re.search(r'([^\sã€€]+(?:æ ªå¼ä¼šç¤¾|åˆåŒä¼šç¤¾|æœ‰é™ä¼šç¤¾)[^\sã€€]*)', title)
            company_name = company_match.group(0) if company_match else title[:10]
            
            all_events.append({
                "title": company_name,
                "start": date_str,
                "extendedProps": {
                    "full_title": title,
                    "summary": entry.get("description", "").replace("<br />", " ").split("ç¶šãã‚’èª­ã‚€")[0],
                    "url": entry.link,
                    "source": source_name,
                    "company": company_name
                }
            })
    return all_events

all_events = fetch_b2b_news()

# --- ãƒ¡ã‚¤ãƒ³ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ ---
st.title("ğŸš€ B2Bã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—åˆ†æ & ææ¡ˆãƒ„ãƒ¼ãƒ«")

col1, col2 = st.columns([1, 1.2])

with col1:
    st.header("ğŸ“… ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼")
    cal = calendar(events=all_events, options={"initialView": "dayGridMonth", "locale": "ja"}, key="cal")
    if cal.get("dateClick"):
        clicked = cal["dateClick"]["date"].split("T")[0]
        if clicked != st.session_state.selected_date:
            st.session_state.selected_date = clicked
            st.rerun()

with col2:
    st.header(f"ğŸ“Œ {st.session_state.selected_date} ã®æ²è¼‰ä¼æ¥­")
    items = [e for e in all_events if e['start'] == st.session_state.selected_date]
    
    if not items:
        st.info("ã“ã®æ—¥ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
    
    for item in items:
        p = item['extendedProps']
        with st.expander(f"[{p['source']}] {p['full_title']}"):
            st.write(f"**ä¼æ¥­å:** {p['company']}")
            st.markdown(f"ğŸ”— [è¨˜äº‹åŸæ–‡ã‚’è¡¨ç¤º]({p['url']})")
            
            btn_key = f"btn_{p['url']}"
            
            # AIææ¡ˆãƒ¡ãƒ¼ãƒ«ã‚’ç”Ÿæˆãƒœã‚¿ãƒ³
            if st.button(f"ğŸ“§ ä¸€æµã‚³ãƒ³ã‚µãƒ«ã®ææ¡ˆãƒ¡ãƒ¼ãƒ«ã‚’ç”Ÿæˆ", key=btn_key):
                # æ—¥ç¨‹ææ¡ˆã®è‡ªå‹•è¨ˆç®—ï¼ˆä»Šæ—¥ã‹ã‚‰2æ—¥å¾Œã€œ5æ—¥é–“ï¼‰
                today = date.today()
                dates = []
                check_day = today + timedelta(days=2)
                while len(dates) < 5:
                    if check_day.weekday() < 5: dates.append(check_day.strftime("%mæœˆ%dæ—¥ï¼ˆ%aï¼‰09:00ï½18:00"))
                    check_day += timedelta(days=1)
                date_text = "\n".join([f"ãƒ»{d}" for d in dates])

                # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆ
                prompt = f"""
                ã‚ãªãŸã¯ã€ä¼æ¥­ã®ãƒ“ã‚¸ãƒã‚¹ãƒ¢ãƒ‡ãƒ«ã¨å“²å­¦ã‚’è¦‹æŠœãè¶…ä¸€æµã®ãƒ“ã‚¸ãƒã‚¹ã‚¢ãƒŠãƒªã‚¹ãƒˆå…¼ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆã§ã™ã€‚
                
                ä»¥ä¸‹ã®ä¼æ¥­ã‚’åˆ†æã—ã€13ä¸‡ç¤¾ã®çµŒå–¶è€…ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’æŒã¤æˆ‘ã€…ã¨ã®ææºãƒ¡ãƒªãƒƒãƒˆã‚’å¼·èª¿ã—ãŸã‚¢ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹ææ¡ˆãƒ¡ãƒ¼ãƒ«ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
                
                ä¼æ¥­å: {p['company']}
                URL: {p['url']}
                è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«: {p['full_title']}
                è¨˜äº‹æ¦‚è¦: {p['summary']}
                è³‡æ–™URL: https://docs.google.com/presentation/d/1JeqlwgvQ4uSaDEtVVdrj9-ju7EpXhKOK/edit

                ã€å¿…é ˆæ¡ä»¶ã€‘
                1. ã‚¹ãƒ†ãƒƒãƒ—0ã€œCã«å¾“ã£ã¦ã€ãƒ“ã‚¸ãƒã‚¹åˆ†æã‚’è©³ã—ãè¡Œã†ã“ã¨ã€‚
                2. æ—¥ç¨‹æ¡ˆã¯ä»¥ä¸‹ã‚’å¿…ãšä½¿ç”¨ã™ã‚‹ã“ã¨ï¼š
                {date_text}
                """

                # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°è¡¨ç¤ºã®é–‹å§‹
                st.divider()
                st.subheader(f"ğŸ¤– {p['company']} ã®åˆ†æçµæœ")
                placeholder = st.empty()
                full_response = ""
                
                try:
                    model = genai.GenerativeModel('gemini-1.5-flash')
                    for chunk in model.generate_content(prompt, stream=True):
                        full_response += chunk.text
                        placeholder.markdown(full_response + "â–Œ") # ã‚¿ã‚¤ãƒ”ãƒ³ã‚°é¢¨
                    
                    placeholder.markdown(full_response)
                    # çµæœã‚’ä¿å­˜
                    st.session_state.ai_results[p['url']] = full_response
                except Exception as e:
                    st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

            # ã™ã§ã«ç”Ÿæˆæ¸ˆã¿ã®çµæœãŒã‚ã‚‹å ´åˆã¯ã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã•ãªãã¦ã‚‚è¡¨ç¤º
            elif p['url'] in st.session_state.ai_results:
                st.divider()
                st.subheader(f"ğŸ¤– {p['company']} ã®ç”Ÿæˆæ¸ˆã¿ææ¡ˆæ¡ˆ")
                st.markdown(st.session_state.ai_results[p['url']])
                st.text_area("ã‚³ãƒ”ãƒšç”¨", value=st.session_state.ai_results[p['url']], height=300, key=f"text_{p['url']}")
